{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our three formats\n",
    "\n",
    "We will learn how to injest (read into pandas):\n",
    "\n",
    "  * csv files\n",
    "  * excel files\n",
    "  * sql files\n",
    "\n",
    "In all cases, we can only read in simple values, if you have formulas in your excel spreadsheet, they are not getting injested into a DataFrame\n",
    "\n",
    "In all cases, the result of injesting data is a pandas `DataFrame``"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically populate a data frame from some external source, the most common being a CSV file.  For this we use the `read_csv` function from the `pandas` library.  We pass it a path to the file we want to load.  On this machine, we are running Linux in the background, so we use Linux-style paths.  Your path would look different on a Windows machine.  Advanced: If you want to run the same code on all computers, [you need a library to build your paths for you](https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "box_hill = pd.read_csv(\"data/rainfall/IDCJAC0009_047045_1800_Data.csv\")\n",
    "box_hill"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A number of very interesting things happen:\n",
    "  1) The dataframe has been given an index that starts at 0 and goes up one at at time.  That data was not in the original CSV file.\n",
    "  2) Any empty cells were given the value `NaN` (which means \"not a number\")\n",
    "  3) The first row is used to create column names (remember a column in a `Series`)\n",
    "  4) When printing the frame, only the first 5 and last 5 rows are shown and the full imensions are shown at the bottom.\n",
    "\n",
    "If we extract one of the series from this frame, it will use the generated indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_hill[\"Rainfall amount (millimetres)\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel\n",
    "\n",
    "Beyond the additional formatting, the primary difference between a CSV file and an Excel file is that the Excel file might have mutliple \"worksheets\", each one of which represents a table that can be imported into a DataFrame.  We have provided an example file with some fun data in `data/fun.xlxs`, here is how to read it using [pandas built-in `read_excel`](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) function.\n",
    "\n",
    "Note: you need to have an additional library installed to make this work:\n",
    "  * [`openpyxl`](https://pythonexamples.org/modulenotfounderror-no-module-named-openpyxl/)\n",
    "\n",
    "You might also note that reading these excel files is _very slow_  because they are very large datasets.\n",
    "\n",
    "If we provide no extra arguments to `read_excel` it will only read the first sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "xx = pd.read_excel(\"data/fun.xlsx\")\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can index other sheets with a number (starting at 0 for the left-most sheet) or by name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data from SQLite\n",
    "\n",
    "Pandas can read data from many sources, lets take a look at an interesting one.  You may have noticed that DataFrames look a lot like database tables?  Indeed you can load a database table directly into a dataframe.\n",
    "\n",
    "Unfortunately, we can't do it all from Pandas, we have to use the `sqlite3` library to load up the database.\n",
    "\n",
    "In the data folder there is a file `data/sql/census200names.sqlite`, we will load the data from this file.  Note:  You need to know the name of the table you want to import!  Databases contain many tables (just like spreadsheets can have many sheets) but there is no default option with sql.  If you don't tell it what table to import, it will five you an error.  Note also that we use a stardard SQL query to get the data.  Here is a table of all the surnames with at least 100 humans attached from ... somewhere?  I think perhaps America?  I can educate my guess by adding up the total number of people accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# we need to use the sqlite library to access the file\n",
    "con = sqlite3.connect(\"data/sql/census2000names.sqlite\")\n",
    "\n",
    "# but then pandas can load up the table\n",
    "df = pd.read_sql(\"SELECT * FROM surnames;\", con)\n",
    "print(df)\n",
    "df[\"count\"].sum()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "242 million?  Sounds about right for the USA.\n",
    "\n",
    "When you don't know what tables are in your sql file, you need to do a little magic to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>businesses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inspections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>violations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name\n",
       "0   businesses\n",
       "1  inspections\n",
       "2   violations"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "con2 = sqlite3.connect(\"data/sql/sfscores.sqlite\")\n",
    "tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", con2)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"select * from businesses;\", con2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"select * from inspections;\", con2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"select * from violations;\", con2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A really nice trick with SQL importing is that you can use any SQL query at all.  Even the most complex SQL queries return a table that can become a DataFrame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise - whr\n",
    "\n",
    "Read in all three sheets (they are called `2015`, `2016`, and `2017`) from the `data/whr.xlsx`.  We've given a sneak-peak of next worksheet's material to combine the three into one data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "whr_2015 = pd.read_excel(\"data/whr.xlsx\", \"2015\") # fixme\n",
    "whr_2016 = pd.read_excel(\"data/whr.xlsx\", \"2016\")# fixme\n",
    "whr_2017 = pd.read_excel(\"data/whr.xlsx\", \"2017\")# fixme\n",
    "\n",
    "all = pd.concat([whr_2015,whr_2016, whr_2017])\n",
    "print(all)\n",
    "print(all.loc[[5,25]])\n",
    "#print(all.loc[all[\"Rank\"]<5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "The following SQL query will return a table from the `sfscores` database.\n",
    "\n",
    "````\n",
    "select * from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "con2 = sqlite3.connect(\"data/sql/sfscores.sqlite\")\n",
    "df = pd.read_sql(\"select * from inspections left join businesses\", con2)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
